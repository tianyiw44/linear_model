---
title: "cross_validation"
output: github_document
date: "2023-11-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Generate a relevant example 

```{r}
n_samp = 250

# dataset with constant variance
sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1,1),
    error = rnorm(n_samp, 0,1),
    y = 2+3 * x + error
  )

# dataset with nonconstant variance
# x value closer to 0 will have smaller error than x value far from 0 due to the error equation
sim_df_nonconst = 
  sim_df_const|>
  mutate(
      error = error *.75 * x,
      y = 2+3 * x + error
  )

sim_df_const |>
  ggplot(aes(x =x, y = y )) +geom_point()

sim_df_nonconst |>
  ggplot(aes(x =x, y = y )) +geom_point()

# variance at intercept (x=0) is low for nonconst, slop of the line should be relatively large becuase the tail is loose

```

fit some linear models

```{r}
sim_df_const |>
  lm(y ~ x, data = _) |>
  broom::tidy()

sim_df_nonconst |>
  lm(y ~ x, data = _) |>
  broom::tidy()

# for nonconst, you can't trust something coming out of lm
```


## draw a bootstrap sample 

start with a lil function 

```{r}
boot_sample = function (df) {

  # use sample_frac(), draw a size from the dataframe of the exact size of the dataframe
  # Key step is replace = true,
  sample_frac(df, replace = TRUE)
  
}
```

Let's see how this work

```{r}
sim_df_nonconst|>
  boot_sample()|>
  ggplot(aes(x=x, y=y)) +
  geom_point(alpha = .5) +
  stat_smooth(method = "lm")

```

## draw a lot of samples and analyze them 

```{r}
boot_straps = 
  tibble(strap_number = 1:100) |>
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(sim_df_nonconst))
  )

boot_straps |>
  pull(strap_sample) |>
  nth(1)|>
  arrange(x)
```

now do the `lm` fit.

```{r}
boot_result = 
  boot_straps |>
  mutate(
    models = map(strap_sample, \(df) lm(y ~ x, data= df)),
    results = map(models, broom:: tidy)
  ) |>
  select(strap_number, results)|>
  unnest(results)

```

try to summarize these results -- get a bootstrap SE

```{r}
boot_result |>
  group_by(term)|>
  summarize(
    se = sd(estimate)
  )

sim_df_nonconst |>
   lm(y ~ x, data = _) |>
   broom::tidy()

# compare the two dataset, the se is reversed and boot_result give us what it should, the intercept should be have smaller se than other x value. 
# if you do everything above for the constant sample, you will get matched/same result
```

look at the distribution 

```{r}
boot_result|>
  filter(term == "x")|>
  ggplot(aes(x = estimate)) +
  geom_density()

#skewed, probably because we only draw 100 bootstrap sample, try 2500
```


can I construct a CI

```{r}
boot_result |>
  group_by(term)|>
  summarize(
    ci_lower = quantile(estimate, 0.025),
    ci_upper = quantile(estimate, 0.075)
  )
```


